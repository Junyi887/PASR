{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import cmocean\n",
    "import h5py\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageFilter\n",
    "from src.models import *\n",
    "import torchaudio\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.ndimage import zoom\n",
    "CMAP = cmocean.cm.balance\n",
    "CMAP = seaborn.cm.icefire\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "import matplotlib.pyplot as plt\n",
    "import radialProfile\n",
    "\n",
    "DATA_INFO = {\"decay_turb\":['../Decay_Turbulence_small/test/Decay_turb_small_128x128_79.h5', 0.02],\n",
    "                 \"burger2d\": [\"../Burgers_2D_small/test/Burgers2D_128x128_79.h5\",0.001],\n",
    "                 \"rbc\": [\"../RBC_small/test/RBC_small_33_s2.h5\",0.01]}\n",
    "                 \n",
    "model_list = {\n",
    "            \"PASR_small\":PASR(upscale=args.scale_factor, in_chans=args.in_channels, img_size=image, window_size=8, depths=[6, 6, 6, 6], embed_dim=60, num_heads=[6, 6, 6, 6], mlp_ratio=2, upsampler=args.upsampler, resi_conv='1conv',mean=mean,std=std,num_ode_layers = args.ode_layer,time_update = args.time_update,ode_kernel_size = args.ode_kernel,ode_padding = args.ode_padding),\n",
    "             \"PASR_MLP_small\":PASR_MLP(upscale=args.scale_factor, in_chans=args.in_channels, img_size=image, window_size=8, depths=[6, 6, 6, 6], embed_dim=60, num_heads=[6, 6, 6, 6], mlp_ratio=2, upsampler=args.upsampler, resi_conv='1conv',mean=mean,std=std),\n",
    "            \"PASR_MLP\":PASR_MLP(upscale=args.scale_factor, in_chans=args.in_channels, img_size=image, window_size=8, depths=[6, 6, 6, 6, 6, 6], embed_dim=180, num_heads=[6, 6, 6, 6, 6, 6], mlp_ratio=2, upsampler=args.upsampler, resi_conv='1conv',mean=mean,std=std),\n",
    "            \"PASR_MLP_G\":PASR_MLP_G(upscale=args.scale_factor, in_chans=args.in_channels, img_size=image, window_size=8, depths=[6, 6, 6, 6, 6, 6], embed_dim=180, num_heads=[6, 6, 6, 6, 6, 6], mlp_ratio=2, upsampler=args.upsampler, resi_conv='1conv',mean=mean,std=std,gating_layers=args.gating_layers,gating_method=args.gating_method),\n",
    "            \"PASR_MLP_small\":PASR_MLP(upscale=args.scale_factor, in_chans=args.in_channels, img_size=image, window_size=8, depths=[6, 6, 6, 6], embed_dim=60, num_heads=[6, 6, 6, 6], mlp_ratio=2, upsampler=args.upsampler, resi_conv='1conv',mean=mean,std=std),\n",
    "            \"PASR_MLP_G_small\":PASR_MLP_G(upscale=args.scale_factor, in_chans=args.in_channels, img_size=image, window_size=8, depths=[6, 6, 6, 6], embed_dim=60, num_heads=[6, 6, 6, 6], mlp_ratio=2, upsampler=args.upsampler, resi_conv='1conv',mean=mean,std=std,gating_layers=args.gating_layers,gating_method=args.gating_method),\n",
    "    }\n",
    "\n",
    "def get_prediction(model,lr_input_tensor,hr_target_tensor,scale_factor,in_channels,task_dt,n_snapshot,ode_step):\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred0 = model(lr_input_tensor.float().cuda(),task_dt = task_dt,n_snapshot = n_snapshot,ode_step = ode_step,time_evol = False)\n",
    "        pred = model(lr_input_tensor.float().cuda(),task_dt = task_dt,n_snapshot = n_snapshot,ode_step = ode_step,time_evol = True)\n",
    "        pred = torch.cat((pred0,pred),dim=1)\n",
    "    return pred.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "def get_metric_RFNE(pred,truth):\n",
    "    RFNE = torch.norm(pred - hr_target_tensor.float().cuda(), p=2, dim=(1, 2, 3)) / torch.norm(hr_target_tensor.float().cuda(), p=2, dim=(1, 2, 3))\n",
    "    avg_RFNE = RFNE.mean().item()\n",
    "    cum_RFNE = torch.norm(pred.flatten()-truth.flatten().float().cuda(),p=2)/torch.norm(truth.flatten().float().cuda(),p=2)\n",
    "    RFNE = torch.norm(pred - truth.float().cuda(), p=2, dim=(1, 2, 3)) / torch.norm(truth.float().cuda(), p=2, dim=(1, 2, 3))\n",
    "    print(f\"averaged RFNE {avg_RFNE}\")\n",
    "    print(f\"cumulative RFNE {cum_RFNE.item()}\")\n",
    "    return avg_RFNE,cum_RFNE.item()\n",
    "\n",
    "model = "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
